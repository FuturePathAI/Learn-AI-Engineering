{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (2.2.0)\n",
      "Requirement already satisfied: transformers in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (4.41.0)\n",
      "Requirement already satisfied: datasets in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (2.14.7)\n",
      "Requirement already satisfied: wandb in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (0.17.0)\n",
      "Requirement already satisfied: filelock in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from datasets) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: xxhash in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from datasets) (3.9.4)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from wandb) (4.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from wandb) (5.9.8)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from wandb) (2.2.0)\n",
      "Requirement already satisfied: setproctitle in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from wandb) (69.2.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First, we need to install the required libraries. Run the following cell to install them.\n",
    "!pip install torch transformers datasets wandb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's import the necessary libraries.\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
    "import wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## Set up Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:zuh0qzpu) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07dfa1e8f1c43f591371c9513976afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-haze-5</strong> at: <a href='https://wandb.ai/futurepath/gpt2-next-word-prediction/runs/zuh0qzpu' target=\"_blank\">https://wandb.ai/futurepath/gpt2-next-word-prediction/runs/zuh0qzpu</a><br/> View project at: <a href='https://wandb.ai/futurepath/gpt2-next-word-prediction' target=\"_blank\">https://wandb.ai/futurepath/gpt2-next-word-prediction</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240522_161355-zuh0qzpu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:zuh0qzpu). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96719cfbdc374cb89523a8ef4031a653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011155417588694642, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sangeethreddy/Documents/Learn-AI-Engineering/notebooks/wandb/run-20240522_161536-q7emdq61</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/futurepath/gpt2-next-word-prediction/runs/q7emdq61' target=\"_blank\">Week4-Lecture0-PyTorch-Introduction.ipynb</a></strong> to <a href='https://wandb.ai/futurepath/gpt2-next-word-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/futurepath/gpt2-next-word-prediction' target=\"_blank\">https://wandb.ai/futurepath/gpt2-next-word-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/futurepath/gpt2-next-word-prediction/runs/q7emdq61' target=\"_blank\">https://wandb.ai/futurepath/gpt2-next-word-prediction/runs/q7emdq61</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights and Biases (W&B) is a tool for experiment tracking. We will use it to log our training metrics.\n",
    "\n",
    "#wandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
    "#wandb: You can find your API key in your browser here: https://wandb.ai/authorize\n",
    "\n",
    "wandb.init(project=\"gpt2-next-word-prediction\", name=\"Week4-Lecture0-PyTorch-Introduction.ipynb\")\n",
    "wandb.login(key=\"3c6858d067cbb8f93980d6f94daa5ea96d42548a\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Data Preparation\n",
    "# ## Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the Wikitext-2 dataset for this tutorial. It is a popular dataset for language modeling tasks.\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at a few examples from the dataset.\n",
    "print(dataset['train'][5]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to tokenize the text data. We will use the GPT-2 tokenizer from HuggingFace's Transformers library.\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a padding token to the tokenizer.\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function to tokenize the dataset.\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True, max_length=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f525bfce6e7f4889909480e7b51866d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b3684f26e343a8864d32584f8f25b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the tokenizer to the dataset.\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '', 'input_ids': [50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Let's check the tokenized data.\n",
    "print(tokenized_datasets['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demo purposes, let's take a small subset of the dataset.\n",
    "def get_subset(dataset, num_samples):\n",
    "    indices = random.sample(range(len(dataset)), num_samples)\n",
    "    return Subset(dataset, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and evaluation sets.\n",
    "# train_dataset = tokenized_datasets['train']\n",
    "# eval_dataset = tokenized_datasets['validation']\n",
    "\n",
    "train_dataset = get_subset(tokenized_datasets['train'], 500)  # 500 samples from training set\n",
    "eval_dataset = get_subset(tokenized_datasets['validation'], 100)  # 100 samples from validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## Define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create DataLoaders to feed the data into our model during training and evaluation.\n",
    "def data_collator(data):\n",
    "    input_ids = torch.tensor([f[\"input_ids\"] for f in data])\n",
    "    attention_mask = torch.tensor([f[\"attention_mask\"] for f in data])\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": input_ids}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=8, collate_fn=data_collator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Model Definition\n",
    "# ## Define GPT-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50258, 768)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use the GPT-2 model from HuggingFace's Transformers library. We need to resize the token embeddings to match the size of our tokenizer.\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## Calculate perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perplexity is a common metric for evaluating language models. It is the exponential of the average negative log-likelihood of a sequence.\n",
    "def calculate_perplexity(loss):\n",
    "    return torch.exp(torch.tensor(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss: 41.99241799574632\n",
      "Perplexity: 1.726134849317634e+18\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate the pretrained model on the validation set. We will calculate the average loss and perplexity.\n",
    "eval_loss_values = []\n",
    "\n",
    "model.eval()\n",
    "eval_loss = 0\n",
    "for batch in eval_dataloader:\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        eval_loss += loss.item()\n",
    "        eval_loss_values.append(loss.item())\n",
    "\n",
    "avg_eval_loss = eval_loss / len(eval_dataloader)\n",
    "perplexity = calculate_perplexity(avg_eval_loss)\n",
    "print(f\"Evaluation Loss: {avg_eval_loss}\")\n",
    "print(f\"Perplexity: {perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Log model with Weights and Biases\n",
    "wandb.watch(model, log=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Training Loop\n",
    "# ## Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sangeethreddy/.virtualenvs/servc_dsk/lib/python3.12/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Let's set up our training parameters. We will train for 3 epochs, use the AdamW optimizer, and set up a learning rate scheduler.\n",
    "epochs = 20\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 4.096096795939264\n",
      "Epoch 2/20, Training Loss: 1.7236736653343079\n",
      "Epoch 3/20, Training Loss: 1.5637030137909784\n",
      "Epoch 4/20, Training Loss: 1.5084220670045367\n",
      "Epoch 5/20, Training Loss: 1.6360897705668496\n",
      "Epoch 6/20, Training Loss: 1.4499379580929166\n",
      "Epoch 7/20, Training Loss: 1.400705458389388\n",
      "Epoch 8/20, Training Loss: 2.8705456025070615\n",
      "Epoch 9/20, Training Loss: 3.8904162560190474\n",
      "Epoch 10/20, Training Loss: 3.1468176619401054\n",
      "Epoch 11/20, Training Loss: 2.978838837809033\n",
      "Epoch 12/20, Training Loss: 2.9443939186277843\n",
      "Epoch 13/20, Training Loss: 2.9242367053788807\n",
      "Epoch 14/20, Training Loss: 2.800061833290827\n",
      "Epoch 15/20, Training Loss: 2.8066132756925763\n",
      "Epoch 16/20, Training Loss: 2.766707059882936\n",
      "Epoch 17/20, Training Loss: 2.753734940810809\n",
      "Epoch 18/20, Training Loss: 2.70892648020434\n",
      "Epoch 19/20, Training Loss: 2.7275393132179504\n",
      "Epoch 20/20, Training Loss: 2.716942758787246\n"
     ]
    }
   ],
   "source": [
    "# Now, we will define the training loop. We will iterate over the training data, perform forward and backward passes, and update the model parameters.\n",
    "training_loss_values = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        wandb.log({\"loss\": loss.item()})\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Save training loss values\n",
    "with open(\"training_loss_values.txt\", \"w\") as f:\n",
    "    for value in training_loss_values:\n",
    "        f.write(f\"{value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss: 2.307636160116929\n",
      "Perplexity: 10.050639152526855\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate the model on the validation set. We will calculate the average loss and perplexity.\n",
    "eval_loss_values = []\n",
    "\n",
    "model.eval()\n",
    "eval_loss = 0\n",
    "for batch in eval_dataloader:\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        eval_loss += loss.item()\n",
    "        eval_loss_values.append(loss.item())\n",
    "\n",
    "avg_eval_loss = eval_loss / len(eval_dataloader)\n",
    "perplexity = calculate_perplexity(avg_eval_loss)\n",
    "print(f\"Evaluation Loss: {avg_eval_loss}\")\n",
    "print(f\"Perplexity: {perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Save evaluation loss values\n",
    "with open(\"eval_loss_values.txt\", \"w\") as f:\n",
    "    for value in eval_loss_values:\n",
    "        f.write(f\"{value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## Plot loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot the training loss curve to visualize the model's performance over time.\n",
    "\n",
    "plt.plot(training_loss_values, label=\"Training Loss\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - PyTorch tutorials: https://pytorch.org/tutorials/\n",
    "# - HuggingFace Transformers: https://huggingface.co/transformers/\n",
    "# - Weights and Biases: https://wandb.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "servc_dsk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
