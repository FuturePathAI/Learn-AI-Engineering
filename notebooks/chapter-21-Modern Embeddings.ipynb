{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "249b0b25-4ec4-4bd8-b0e8-0f84a6fe026d",
   "metadata": {},
   "source": [
    "# Modern Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4665a9a-ed5f-4d7c-8167-c2662225953f",
   "metadata": {},
   "source": [
    "- Modern embeddings have advanced significantly beyond the initial word embedding techniques like Word2Vec, GloVe, and FastText, addressing some of their limitations, especially in context sensitivity and handling polysemy.\n",
    "- The advent of contextual embeddings like ELMo, BERT (Bidirectional Encoder Representations from Transformers), and GPT (Generative Pre-trained Transformer) has revolutionized how machines understand human language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91e388f-849a-4aa7-886d-0c0dadc79af5",
   "metadata": {},
   "source": [
    "### Contextual Embeddings: A Deeper Understanding\n",
    "Contextual embeddings differ from traditional word embeddings by providing representations that consider the context in which a word appears. This means that the same word can have different embeddings based on its surrounding words, allowing for a much richer understanding of language nuances.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e943bf2a-3971-48da-b036-c31d21359faf",
   "metadata": {},
   "source": [
    "### ELMo (Embeddings from Language Models)\n",
    "ELMo, developed by Allen Institute for AI, was one of the first to offer deep contextualized word representations. It uses a bidirectional LSTM trained on a specific task to generate embeddings for words based on their context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ac2e0b-d41c-40fe-97a0-00ef08e91739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install allennlp==2.1.0 allennlp-models==2.1.0\n",
    "\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "\n",
    "# ELMo uses 2 layers by default, so we specify the output dimension for each.\n",
    "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
    "\n",
    "# Initialize the ELMo model\n",
    "elmo = Elmo(options_file, weight_file, num_output_representations=1, dropout=0)\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\"I have a pen\", \"I have an apple\"]\n",
    "\n",
    "# Convert sentences to character ids\n",
    "character_ids = batch_to_ids(sentences)\n",
    "\n",
    "# Generate embeddings\n",
    "with torch.no_grad():\n",
    "    embeddings = elmo(character_ids)\n",
    "\n",
    "# embeddings['elmo_representations'] is a list of tensor embeddings for each layer.\n",
    "# For simplicity, we'll use the first layer.\n",
    "elmo_embeddings = embeddings['elmo_representations'][0]\n",
    "\n",
    "print(\"Shape of ELMo embeddings:\", elmo_embeddings.shape)\n",
    "# Shape: [batch size, sequence length, embedding dimension], e.g., [2, 5, 1024] for the above sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7821923-8e42-4b78-b945-4e7559462950",
   "metadata": {},
   "source": [
    "### BERT (Bidirectional Encoder Representations from Transformers)\n",
    "BERT, developed by Google, takes contextual embeddings further by using the Transformer architecture. It pre-trains on a large corpus with two tasks: masked word prediction and next sentence prediction, allowing it to understand context and relationships within text deeply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f15680-3d70-467a-9d73-4ffe564d6cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Sample text\n",
    "text = \"Here is some text to encode\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# Generate embeddings\n",
    "with torch.no_grad():\n",
    "    output = model(**encoded_input)\n",
    "\n",
    "# The last hidden state is the sequence of hidden states of the last layer of the model\n",
    "last_hidden_states = output.last_hidden_state\n",
    "\n",
    "print(\"Shape of embeddings:\", last_hidden_states.shape)\n",
    "# Shape: [batch size, sequence length, hidden size], e.g., [1, 7, 768] for 'bert-base-uncased'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef2e141-4e91-4b62-8ccc-b74a7d23ac78",
   "metadata": {},
   "source": [
    "### GPT (Generative Pre-trained Transformer)\n",
    "GPT, by OpenAI, extends the idea of using transformers for generating contextual embeddings. Unlike BERT, GPT is unidirectional but pre-trained on a massive scale, making it highly effective in generating human-like text and understanding context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6d4c3a-5246-43a8-871c-31717aac8048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for GPT Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91530042-f41c-4ec2-ac9f-adbb5a1858c8",
   "metadata": {},
   "source": [
    "### Contextual vs Non-contextual Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d91c939-e61d-4353-8d67-d1e80b8fcf29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
