{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "359bcf98-f5be-4c91-ba0a-a3ae11def7c8",
   "metadata": {},
   "source": [
    "# Lession: RAG Retrieval Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37b6a47-d652-444c-adfb-d5c34d31c0d5",
   "metadata": {},
   "source": [
    "### RAGAS\n",
    "\n",
    "\n",
    "The ragas library focuses on metrics that are directly applicable to RAG models. The metrics you mentioned are:\n",
    "\n",
    "- **Context Precision**: Measures the precision of the context retrieved by the RAG model. It evaluates how accurately the retrieved documents or context segments are relevant to the query.\n",
    "\n",
    "- **Faithfulness**: Assesses how faithfully the generated response represents the information in the retrieved documents. This is crucial in ensuring that the RAG model's output is not only relevant but also accurately reflects the source material.\n",
    "\n",
    "- **Answer Relevancy**: Evaluates the relevancy of the generated answer to the query. This is essential for tasks like question answering, where the goal is to provide accurate and relevant answers based on the retrieved context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114684d3-4278-4dd5-83cf-cd6301dc541e",
   "metadata": {},
   "source": [
    "# Other Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce1bc20-a508-459d-b0ea-0b364366f94a",
   "metadata": {},
   "source": [
    "1. Context Recall:\n",
    "While precision focuses on the relevance of retrieved documents, recall assesses the model's ability to retrieve all relevant documents from the dataset. This is important in contexts where missing key information can lead to incomplete or inaccurate responses.\n",
    "\n",
    "2. ROGUE:\n",
    "3. BLUE\n",
    "4. PERPLEXITY\n",
    "5. Logprobs from OpenAI\n",
    "\n",
    "6. Retrieval Diversity:\n",
    "Evaluates the variety in the retrieved documents. High diversity ensures that the model is not just retrieving similar documents but is considering a wide range of potentially relevant information.\n",
    "\n",
    "7. Query-Document Alignment:\n",
    "This involves assessing how well the model's query representation aligns with the document representations in its database. Misalignment can lead to retrieval errors, where the model retrieves documents that are semantically distant from the query.\n",
    "\n",
    "8. Ranking Accuracy:\n",
    "Evaluates how accurately the model ranks the retrieved documents in order of relevance. Higher-ranking accuracy ensures that the most relevant documents are considered first for generating responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642fa6c5-f62a-4ddb-b94d-48439895eb7b",
   "metadata": {},
   "source": [
    "# Lesson: Synthetic Test Data Generation\n",
    "\n",
    "- We are provided with a dataset to build RAG system on\n",
    "- We can either manually generate QA from that data set for evaluation purpose, or\n",
    "- We can synthetically generate QA data. Let's see how we do that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3bfc11-d839-4526-bbe0-d313f85a2908",
   "metadata": {},
   "source": [
    "### Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fccd84a-c6a3-4e49-be3a-d225a2728bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the OpenAI API key\n",
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY_FUTUREPATH_ML')\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "176501c5-862e-4b85-aeb3-6609f71a5260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.10s/it]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\"../data/paul_graham\", show_progress=True)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce60fc4-8ecc-4d4a-a65d-16cf3291ec0e",
   "metadata": {},
   "source": [
    "### Generate Synthetic Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a04de7-f675-4c51-9d98-013f7ee3d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from ragas.llms import LangchainLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4464f1d9-4ebd-4692-b8d5-781ad0c5b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom llms and embeddings\n",
    "generator_llm = LangchainLLM(llm=ChatOpenAI(model=\"gpt-3.5-turbo\"))\n",
    "critic_llm = LangchainLLM(llm=ChatOpenAI(model=\"gpt-4\"))\n",
    "embeddings_model = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8731de-b93b-48ae-9919-0b5276d6296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change resulting question type distribution\n",
    "testset_distribution = {\n",
    "    \"simple\": 0.25,\n",
    "    \"reasoning\": 0.5,\n",
    "    \"multi_context\": 0.0,\n",
    "    \"conditional\": 0.25,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50589497-d7ee-4fb1-a259-e69c9815dbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                  | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|████████████████████████▍                                                                                                 | 1/5 [00:26<01:46, 26.56s/it]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████████████████████████████▏                                                | 3/5 [01:21<00:54, 27.41s/it]\u001b[A\n",
      "6it [01:36, 13.56s/it]                                                                                                                                       \u001b[A\n",
      "10it [02:09, 10.73s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "# percentage of conversational question\n",
    "chat_qa = 0.2\n",
    "\n",
    "test_generator = TestsetGenerator(\n",
    "    generator_llm=generator_llm,\n",
    "    critic_llm=critic_llm,\n",
    "    embeddings_model=embeddings_model,\n",
    "    testset_distribution=testset_distribution,\n",
    "    chat_qa=chat_qa,\n",
    ")\n",
    "testset = test_generator.generate(documents, test_size=5)\n",
    "\n",
    "\n",
    "testset_df= testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585785b8-6039-4743-8fdd-374d4cc3c1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:37, 15.76s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth_context</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>question_type</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What factors influenced the choice to start Y ...</td>\n",
       "      <td>[The prospect of having to stand up in front o...</td>\n",
       "      <td>[The factors that influenced the choice to sta...</td>\n",
       "      <td>conditional</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What prompted Jessica Livingston to compile a ...</td>\n",
       "      <td>[Jessica was surprised by the disparities betw...</td>\n",
       "      <td>[The disparities between her bank's perception...</td>\n",
       "      <td>conditional</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What inspired Jessica Livingston to compile a ...</td>\n",
       "      <td>[One of the guests was someone I didn't know b...</td>\n",
       "      <td>[The information from the given context does n...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Could online store software be operated on a s...</td>\n",
       "      <td>[What if we ran the software on the server, an...</td>\n",
       "      <td>[Yes, online store software could be operated ...</td>\n",
       "      <td>conditional</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What factors influenced the choice to start Y ...   \n",
       "1  What prompted Jessica Livingston to compile a ...   \n",
       "2  What inspired Jessica Livingston to compile a ...   \n",
       "3  Could online store software be operated on a s...   \n",
       "\n",
       "                                ground_truth_context  \\\n",
       "0  [The prospect of having to stand up in front o...   \n",
       "1  [Jessica was surprised by the disparities betw...   \n",
       "2  [One of the guests was someone I didn't know b...   \n",
       "3  [What if we ran the software on the server, an...   \n",
       "\n",
       "                                        ground_truth question_type  \\\n",
       "0  [The factors that influenced the choice to sta...   conditional   \n",
       "1  [The disparities between her bank's perception...   conditional   \n",
       "2  [The information from the given context does n...        simple   \n",
       "3  [Yes, online store software could be operated ...   conditional   \n",
       "\n",
       "   episode_done  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7e7c3b-6d9a-40c7-b3c0-ef70ae2750f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What factors influenced the choice to start Y Combinator as an angel firm instead of raising a fund and how was the batch model for funding startups developed?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_df.question[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf051d5-c50c-4d62-8c64-62fb286dd966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Jessica was surprised by the disparities between her bank's perception of startups and the actuality after meeting friends from the startup world.\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_df.ground_truth_context[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d9b41-2fd8-4967-8ed1-fe2b9e189fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The factors that influenced the choice to start Y Combinator as an angel firm instead of raising a fund were the belief that successful startup founders would be the best sources of seed funding and advice, and the desire to stop procrastinating about angel investing. The batch model for funding startups was developed as a way to fund a bunch of startups at once and gain experience as investors.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_df.ground_truth[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229b000-8eea-4040-88d5-d92aefd5ebd1",
   "metadata": {},
   "source": [
    "### Compute Responses using RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06af083-f32f-4eb7-8ae1-606a4f6badc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_langchain import RAGLangchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7800c69-6fe9-4832-8961-e00a228c6e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████████                                                                  | 1/2 [00:00<00:00,  3.34it/s]\n"
     ]
    }
   ],
   "source": [
    "rag = RAGLangchain(input_dir=\"./data/paul_graham\", persist_dir=\"./vectordb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf8d5ad-7506-439e-bce1-f9ad0c551d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maruti/work/mercury_ml/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output_text': \"The text doesn't provide information on whether Paul Graham met Sam Altman.\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.get_response(\"Did paul graham meet Sam altman?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30464ee3-eb60-4579-a3dc-9928e5d2141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get RAG response for each question\n",
    "def get_rag_response(question):\n",
    "    try:\n",
    "        response = rag.get_response(question)\n",
    "        return response.get('output_text')\n",
    "    except Exception as e:\n",
    "        print(f\"Error while getting response for question '{question}': {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00b13b1-4c32-4c8d-b577-7b21267eeee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 108 ms, sys: 63.3 ms, total: 172 ms\n",
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "testset_df['llm_response'] = testset_df['question'].apply(get_rag_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a70946-ba48-4b94-9706-2fb899c30287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth_context</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>question_type</th>\n",
       "      <th>episode_done</th>\n",
       "      <th>llm_response</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What factors influenced the choice to start Y ...</td>\n",
       "      <td>[The prospect of having to stand up in front o...</td>\n",
       "      <td>[The factors that influenced the choice to sta...</td>\n",
       "      <td>conditional</td>\n",
       "      <td>True</td>\n",
       "      <td>The decision to start Y Combinator as an angel...</td>\n",
       "      <td>[[The prospect of having to stand up in front ...</td>\n",
       "      <td>[The decision to start Y Combinator as an ange...</td>\n",
       "      <td>[[The factors that influenced the choice to st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What inspired the idea of running software on ...</td>\n",
       "      <td>[One morning as I was lying on this mattress I...</td>\n",
       "      <td>[The idea of running software on the server an...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "      <td>The idea of running software on the server and...</td>\n",
       "      <td>[[One morning as I was lying on this mattress ...</td>\n",
       "      <td>[The inspiration for the idea of running softw...</td>\n",
       "      <td>[[The idea of running software on the server a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What inspired Jessica Livingston to compile a ...</td>\n",
       "      <td>[One of the guests was someone I didn't know b...</td>\n",
       "      <td>[The information from the given context does n...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "      <td>Jessica was inspired to compile a book of inte...</td>\n",
       "      <td>[[One of the guests was someone I didn't know ...</td>\n",
       "      <td>[Jessica was inspired to compile a book of int...</td>\n",
       "      <td>[[The information from the given context does ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What factors influenced the choice to start Y ...   \n",
       "1  What inspired the idea of running software on ...   \n",
       "2  What inspired Jessica Livingston to compile a ...   \n",
       "\n",
       "                                ground_truth_context  \\\n",
       "0  [The prospect of having to stand up in front o...   \n",
       "1  [One morning as I was lying on this mattress I...   \n",
       "2  [One of the guests was someone I didn't know b...   \n",
       "\n",
       "                                        ground_truth question_type  \\\n",
       "0  [The factors that influenced the choice to sta...   conditional   \n",
       "1  [The idea of running software on the server an...        simple   \n",
       "2  [The information from the given context does n...        simple   \n",
       "\n",
       "   episode_done                                       llm_response  \\\n",
       "0          True  The decision to start Y Combinator as an angel...   \n",
       "1          True  The idea of running software on the server and...   \n",
       "2          True  Jessica was inspired to compile a book of inte...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [[The prospect of having to stand up in front ...   \n",
       "1  [[One morning as I was lying on this mattress ...   \n",
       "2  [[One of the guests was someone I didn't know ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  [The decision to start Y Combinator as an ange...   \n",
       "1  [The inspiration for the idea of running softw...   \n",
       "2  [Jessica was inspired to compile a book of int...   \n",
       "\n",
       "                                       ground_truths  \n",
       "0  [[The factors that influenced the choice to st...  \n",
       "1  [[The idea of running software on the server a...  \n",
       "2  [[The information from the given context does ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb6493-7f59-4d6c-92cd-ae8b9145213e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('O'),\n",
       " [\"The prospect of having to stand up in front of a group of people and tell them something that won't waste their time is a great spur to the imagination.\\nWhen the Harvard Computer Society, the undergrad computer club, asked me to give a talk, I decided I would tell them how to start a startup.\\nSo I gave this talk, in the course of which I told them that the best sources of seed funding were successful startup founders, because then they'd be sources of advice too.\\nBut afterward it occurred to me that I should really stop procrastinating about angel investing.\\nWe'd start our own investment firm and actually implement the ideas we'd been talking about.\\nThere were VC firms, which were organized companies with people whose job it was to make investments, but they only did big, million dollar investments.\\nAnd there were angels, who did smaller investments, but these were individuals who were usually focused on other things and made investments on the side.\\nOur plan was not only to make seed investments, but to do for startups everything Julian had done for us.\\nYC was not organized as a fund. It was cheap enough to run that we funded it with our own money.\\nThe most distinctive thing about YC is the batch model: to fund a bunch of startups all at once, twice a year, and then to spend three months focusing intensively on trying to help them.\\nWe needed to get experience as investors. What better way, we thought, than to fund a whole bunch of startups at once?\"])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_df.ground_truth_context.dtype, testset_df.ground_truth_context[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf6dd52-20bc-472e-8118-0d17313a73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, Features, Sequence, Value\n",
    "\n",
    "def convert_to_hf_dataset(testset_df):\n",
    "    \"\"\"\n",
    "    Convert a pandas DataFrame into a Hugging Face Dataset with the required format.\n",
    "\n",
    "    Parameters:\n",
    "    testset_df (pd.DataFrame): DataFrame containing the data in the format \n",
    "                               ['question', 'ground_truth_context', 'ground_truth', 'question_type', \n",
    "                                'episode_done', 'llm_response']\n",
    "\n",
    "    Returns:\n",
    "    Dataset: A Hugging Face Dataset ready for evaluation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare the DataFrame for conversion\n",
    "    testset_df['contexts'] = testset_df['ground_truth_context'].apply(lambda x: [x] if isinstance(x, str) else x)\n",
    "    testset_df['answer'] = testset_df['llm_response'].apply(lambda x: str(x))\n",
    "    testset_df['ground_truths'] = testset_df['ground_truth'].apply(lambda x: [x] if isinstance(x, str) else x)\n",
    "\n",
    "    # Define the dataset features using Features\n",
    "    features = Features({\n",
    "        'question': Value('string'),\n",
    "        'contexts': Sequence(Value('string')),\n",
    "        'answer': Value('string'),\n",
    "        'ground_truths': Sequence(Value('string')),\n",
    "    })\n",
    "\n",
    "    # Convert to Hugging Face Dataset\n",
    "    hf_dataset = Dataset.from_pandas(testset_df[['question', 'contexts', 'answer', 'ground_truths']], features=features)\n",
    "\n",
    "    return hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb4144f-eaa1-43dc-b7a5-719b3c98fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = convert_to_hf_dataset(testset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c34b9b3-57e8-4b5e-939a-bce511e3c9d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfinal_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e596004b-f2a3-4ac7-a1e0-6d587c86fc7b",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349327e-9f24-4a6a-8b9b-1e841950292d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.84s/it]\n",
      "/Users/maruti/work/mercury_ml/.venv/lib/python3.10/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/Users/maruti/work/mercury_ml/.venv/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "/Users/maruti/work/mercury_ml/.venv/lib/python3.10/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/Users/maruti/work/mercury_ml/.venv/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.84s/it]\n",
      "/Users/maruti/work/mercury_ml/.venv/lib/python3.10/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/Users/maruti/work/mercury_ml/.venv/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.21s/it]\n",
      "/Users/maruti/work/mercury_ml/.venv/lib/python3.10/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/Users/maruti/work/mercury_ml/.venv/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer_relevancy': 0.9772, 'context_precision': 1.0000, 'faithfulness': 0.1667, 'context_recall': 0.6667}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.evaluation import evaluate\n",
    "\n",
    "\n",
    "evaluate(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99980256-b159-4236-bdad-deecd9ce4e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
