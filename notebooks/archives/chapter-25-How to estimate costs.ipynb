{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d1333fa-1a7c-4df9-9435-49ac4f056b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from learn_ai.scripts.utils import chat_completion_request_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a93c7f04-4323-4942-9be2-09d57a41e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cost per million tokens for each model\n",
    "COST_MILLION_TOKENS = {\n",
    "    \"gpt-4\": {\"input\": 0.02, \"output\": 0.06},\n",
    "    \"gpt-4-0125-preview\": {\"input\": 0.02, \"output\": 0.06},\n",
    "    \"gpt-4-1106-preview\": {\"input\": 0.02, \"output\": 0.06},\n",
    "    \"gpt-4-1106-vision-preview\": {\"input\": 0.02, \"output\": 0.06},\n",
    "    \"gpt-3.5-turbo-0613\": {\"input\": 0.01, \"output\": 0.02},\n",
    "    \"gpt-3.5-turbo-0125\": {\"input\": 0.01, \"output\": 0.02},\n",
    "    \"gpt-3.5-turbo-instruct\": {\"input\": 0.01, \"output\": 0.02}\n",
    "}\n",
    "\n",
    "# Calculate cost based on token counts and model type\n",
    "def calculate_cost(total_tokens, input_tokens, output_tokens, model_type):\n",
    "    input_cost = (input_tokens / 1e6) * COST_MILLION_TOKENS[model_type]['input']\n",
    "    output_cost = (output_tokens / 1e6) * COST_MILLION_TOKENS[model_type]['output']\n",
    "    total_cost = input_cost + output_cost\n",
    "    return total_cost, input_cost, output_cost\n",
    "\n",
    "# Update and log costs after each chat interaction\n",
    "class CostLogger:\n",
    "    def __init__(self):\n",
    "        self.costs = {\"total_cost\": 0, \"total_input_cost\": 0, \"total_output_cost\": 0, \"costs_per_model\": {}}\n",
    "        self.token_count = {\"total_token\": 0, \"total_input_token\": 0, \"total_output_token\": 0, \"token_per_model\": {}}\n",
    "        \n",
    "    def update_cost_after_chat(self, tokens, model_type):\n",
    "        total_tokens, input_tokens, output_tokens = tokens\n",
    "        total_cost, input_cost, output_cost = calculate_cost(total_tokens, input_tokens, output_tokens, model_type)\n",
    "        self.costs[\"total_cost\"] += total_cost\n",
    "        self.costs[\"total_input_cost\"] += input_cost\n",
    "        self.costs[\"total_output_cost\"] += output_cost\n",
    "        self.costs.setdefault(\"costs_per_model\", {}).setdefault(model_type, {\"total\": 0, \"input\": 0, \"output\": 0})\n",
    "        self.costs[\"costs_per_model\"][model_type][\"total\"] += total_cost\n",
    "        self.costs[\"costs_per_model\"][model_type][\"input\"] += input_cost\n",
    "        self.costs[\"costs_per_model\"][model_type][\"output\"] += output_cost\n",
    "        logging.info(self.costs)\n",
    "\n",
    "    def log_costs(self):\n",
    "        print(f\"Total cost for conversation: ${self.costs['total_cost']:.8f}\")\n",
    "        print(f\"Total input cost: ${self.costs['total_input_cost']:.8f}\")\n",
    "        print(f\"Total output cost: ${self.costs['total_output_cost']:.8f}\")\n",
    "        for model, costs in self.costs[\"costs_per_model\"].items():\n",
    "            print(f\"Costs for {model}: Total: ${costs['total']:.8f}, Input: ${costs['input']:.8f}, Output: ${costs['output']:.8f}\")\n",
    "\n",
    "    def update_tokens_after_chat(self, tokens, model_type):\n",
    "        total_tokens, input_tokens, output_tokens = tokens\n",
    "        self.token_count[\"total_token\"] += total_tokens\n",
    "        self.token_count[\"total_input_token\"] += input_tokens\n",
    "        self.token_count[\"total_output_token\"] += output_tokens\n",
    "        self.token_count.setdefault(\"token_per_model\", {}).setdefault(model_type, {\"input\": 0, \"output\": 0})\n",
    "        self.token_count[\"token_per_model\"][model_type][\"input\"] += input_tokens\n",
    "        self.token_count[\"token_per_model\"][model_type][\"output\"] += output_tokens\n",
    "        logging.info(f\"Updated token counts after chat for model {model_type}: {self.token_count}\")\n",
    "\n",
    "    def log_tokens(self):\n",
    "        print(f\"Total tokens for conversation: {self.token_count['total_token']}\")\n",
    "        print(f\"Total input tokens: {self.token_count['total_input_token']}\")\n",
    "        print(f\"Total output tokens: {self.token_count['total_output_token']}\")\n",
    "        for model, token_counts in self.token_count[\"token_per_model\"].items():\n",
    "            print(f\"Tokens for {model}: Input: {token_counts['input']}, Output: {token_counts['output']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9135fcd-1379-44db-9ea3-158814f37148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:{'total_cost': 4.9e-07, 'total_input_cost': 3.1e-07, 'total_output_cost': 1.8e-07, 'costs_per_model': {'gpt-3.5-turbo-0125': {'total': 4.9e-07, 'input': 3.1e-07, 'output': 1.8e-07}}}\n",
      "INFO:Updated token counts after chat for model gpt-3.5-turbo-0125: {'total_token': 40, 'total_input_token': 31, 'total_output_token': 9, 'token_per_model': {'gpt-3.5-turbo-0125': {'input': 31, 'output': 9}}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost for conversation: $0.00000049\n",
      "Total input cost: $0.00000031\n",
      "Total output cost: $0.00000018\n",
      "Costs for gpt-3.5-turbo-0125: Total: $0.00000049, Input: $0.00000031, Output: $0.00000018\n",
      "Total tokens for conversation: 40\n",
      "Total input tokens: 31\n",
      "Total output tokens: 9\n",
      "Tokens for gpt-3.5-turbo-0125: Input: 31, Output: 9\n"
     ]
    }
   ],
   "source": [
    "cost_logger = CostLogger()\n",
    "\n",
    "# Simulate sending messages and getting a completion\n",
    "model_type = 'gpt-3.5-turbo-0125'\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm good, thank you! How can I assist you today?\"}\n",
    "]\n",
    "\n",
    "# Assume the function returns the completion and token counts\n",
    "_, tokens = chat_completion_request_tokens(messages, model=model_type)\n",
    "\n",
    "# Update and log the costs based on the tokens used\n",
    "cost_logger.update_cost_after_chat(tokens, model_type)\n",
    "cost_logger.log_costs()\n",
    "\n",
    "# Log the token counts for teaching purposes\n",
    "cost_logger.update_tokens_after_chat(tokens, model_type)\n",
    "cost_logger.log_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb84e25-fddb-4ff5-9e74-cbce10bae469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
