{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdcc1fec-51e2-4d7d-8fdb-7447fee9e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from learn_ai.scripts.utils import chat_completion_request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d6d42f-4b18-496c-af16-c1a4fe158222",
   "metadata": {},
   "source": [
    "# Lesson 1: Zero Shot Prompting\n",
    "\n",
    "- The word \"shot\" is synonymous with \"example\"\n",
    "- Zero-shot prompting can be likened to requesting someone to undertake a task they have no prior experience in, without providing any examples or guidelines.\n",
    "- Consider the scenario where you ask a friend, who has never engaged in cooking, to bake a cake. You don't provide a recipe or any demonstrations; they must depend entirely on their existing knowledge or assumptions about baking.\n",
    "- In the realm of artificial intelligence, zero-shot prompting operates in a comparable manner. Here, the AI employs its inherent knowledge, acquired during its training phase, to attempt a task for which it hasn't been explicitly prepared or shown specific examples.\n",
    "- This approach tests the AI's ability to apply its general understanding to new and unseen challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3332064-e89b-4cb5-bc3d-9ca71e95c3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Emily Johnson [Educator]\n",
      "- Michael Smith [Tech Innovator]\n",
      "- John Doe [Pastry Chef]\n",
      "- Jane Smith [Architect]\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot example for extracting names and occupations\n",
    "zero_shot_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a model that extracts names and occupations from text.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Read the following article and list the names and occupations in the format 'First Last [OCCUPATION]': \\\n",
    "                    'In today's town news, we celebrate Emily Johnson, who has dedicated over two decades to enlightening young \\\n",
    "                    minds in our local schools, being named Educator of the Year. Meanwhile, a visionary in the tech world, Michael Smith, \\\n",
    "                    is spearheading an innovative venture in sustainable technology. Also in the news, renowned pastry chef John Doe is set \\\n",
    "                    to host a baking masterclass, while Jane Smith, known for her architectural prowess, has unveiled plans for a new city park.'\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Call the function with zero-shot prompting\n",
    "zero_shot_response = chat_completion_request(messages=zero_shot_messages)\n",
    "print(zero_shot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2615c2d1-6e4a-46f8-b439-8e7b31bf2cd4",
   "metadata": {},
   "source": [
    "# Lesson 2: Few Shot Prompting\n",
    "\n",
    "- Few-shot prompting is akin to asking someone to perform a task with the aid of a few examples.\n",
    "- The AI is presented with a small number of examples before tackling a new task. These examples serve as a learning aid, enabling the AI to grasp the task's context and desired output.\n",
    "- This method enhances the AI's ability to adapt its pre-existing knowledge to tasks it was not explicitly trained for, using the provided examples as a learning reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c64560-930f-434f-a35b-545bfb3abcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emily Johnson [EDUCATOR]\n",
      "Michael Smith [TECH ENTREPRENEUR]\n",
      "John Doe [PASTRY CHEF]\n",
      "Jane Smith [ARCHITECT]\n"
     ]
    }
   ],
   "source": [
    "# Few-shot example for extracting names and occupations\n",
    "few_shot_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a model that extracts names and occupations from text.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Example: Article text: 'John Doe, renowned for his exquisite pastries, has won numerous awards.' Output: John Doe [PASTRY CHEF]\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Example: Article text: 'Architect Jane Smith received acclaim for her innovative building designs.' Output: Jane Smith [ARCHITECT]\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Read the following article and list the names and occupations in the format 'First Last [OCCUPATION]': 'In today's town news, we celebrate Emily Johnson, who has dedicated over two decades to enlightening young minds in our local schools, being named Educator of the Year. Meanwhile, a visionary in the tech world, Michael Smith, is spearheading an innovative venture in sustainable technology. Also in the news, renowned pastry chef John Doe is set to host a baking masterclass, while Jane Smith, known for her architectural prowess, has unveiled plans for a new city park.'\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Call the function with few-shot prompting\n",
    "few_shot_response = chat_completion_request(messages=few_shot_messages)\n",
    "print(few_shot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816065f4-2258-4f85-9106-d7677f5a4794",
   "metadata": {},
   "source": [
    "## Limitations of Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b541551-812b-46ac-9ea4-87a8af54fa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's first calculate the sum of odd numbers in the group:\n",
      "\n",
      "15 + 5 + 13 + 39 + 67 + 7 + 1 = 147\n",
      "\n",
      "Now, let's calculate twice the sum of even numbers in the group:\n",
      "\n",
      "2*(32 + 82 + 48 + 26) = 2*(188) = 376\n",
      "\n",
      "Finally, let's subtract twice the sum of even numbers from the sum of odd numbers:\n",
      "\n",
      "147 - 376 = -229\n",
      "\n",
      "The result is -229, which is an odd number. Therefore, the answer is True.\n"
     ]
    }
   ],
   "source": [
    "# Enhanced few-shot example for a more complex reasoning task\n",
    "few_shot_messages_complex_reasoning = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a model that solves complex numerical reasoning problems.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"The sum of odd numbers in this group minus the sum of even numbers results in an odd number: 4, 8, 9, 15, 12, 2, 1. The answer is False.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"The sum of odd numbers in this group minus the sum of even numbers results in an odd number: 17, 10, 19, 4, 8, 12, 24. The answer is True.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"The sum of odd numbers in this group minus twice the sum of even numbers results in an odd number: 15, 32, 5, 13, 82, 39, 67, 7, 1, 48, 26. The answer is?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Call the function with few-shot prompting for complex reasoning\n",
    "few_shot_response_complex_reasoning = chat_completion_request(messages=few_shot_messages_complex_reasoning)\n",
    "print(few_shot_response_complex_reasoning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8137bb32-d297-4c81-b25c-91b7c681f1b9",
   "metadata": {},
   "source": [
    "## Tips for Effective Few-Shot Prompting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11055e6d-f4d4-4e3b-a88e-641308e5ff1d",
   "metadata": {},
   "source": [
    "### Distribution of Input Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5270b55-daad-4929-9253-f49d1c4ebba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hippopotamus is a Mammal.\n"
     ]
    }
   ],
   "source": [
    "# few-shot example with two categories\n",
    "few_shot_messages = [\n",
    "    {\"role\": \"system\",\"content\": \"You are a model that classifies animals into categories: Mammal or Bird.\"},\n",
    "    \n",
    "    {\"role\": \"user\",\"content\": \"Classify the following animal: Kangaroo.\"},\n",
    "    {\"role\": \"assistant\",\"content\": \"Kangaroo is a Mammal.\"},\n",
    "    \n",
    "    {\"role\": \"user\",\"content\": \"Classify the following animal: Elephant.\"},\n",
    "    {\"role\": \"assistant\",\"content\": \"Elephant is a Mammal.\"},\n",
    "    \n",
    "    {\"role\": \"user\",\"content\": \"Classify the following animal: Penguin.\"},\n",
    "    {\"role\": \"assistant\",\"content\": \"Penguin is a Bird.\"},\n",
    "    \n",
    "    {\"role\": \"user\",\"content\": \"Classify the following animal: Eagle.\"},\n",
    "    {\"role\": \"assistant\",\"content\": \"Eagle is a Bird.\"},\n",
    "    \n",
    "    {\"role\": \"user\",\"content\": \"Classify the following animal: Hippopotomus.\"}\n",
    "]\n",
    "\n",
    "# Call the function with revised few-shot prompting for two categories\n",
    "category = chat_completion_request(messages=few_shot_messages)\n",
    "print(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e31af65-d97b-4761-b042-f8836659da5b",
   "metadata": {},
   "source": [
    "### Consistentcy in format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ebafd3-208c-476d-ba2c-ed240cbc576f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C'est une belle journée.\n"
     ]
    }
   ],
   "source": [
    "# Few-shot example with consistent format for translation\n",
    "consistent_format_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a model that translates English sentences to French.\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Translate: 'Hello, how are you?'\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Bonjour, comment ça va?\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Translate: 'What is your name?'\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Comment vous appelez-vous?\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Translate: 'I am learning French.'\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"J'apprends le français.\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Translate: 'This is a beautiful day.'\"}\n",
    "]\n",
    "\n",
    "# Call the function with consistent format for translation\n",
    "consistent_translation = chat_completion_request(messages=consistent_format_messages)\n",
    "print(consistent_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a9678e-a727-4723-bb5a-a00437887e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Où est la station la plus proche ?\n"
     ]
    }
   ],
   "source": [
    "# Few-shot example with inconsistent format for translation\n",
    "inconsistent_format_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a model that translates English sentences to French.\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"How do you say in French: 'Good morning'?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Bonjour.\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"Translate this: 'I like to travel.'\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"J'aime voyager.\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"'It's raining today' in French is?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Il pleut aujourd'hui.\"},\n",
    "    \n",
    "    {\"role\": \"user\", \"content\": \"How would you translate 'Where is the nearest station?' to French?\"}\n",
    "]\n",
    "\n",
    "# Call the function with inconsistent format for translation\n",
    "inconsistent_translation = chat_completion_request(messages=inconsistent_format_messages)\n",
    "print(inconsistent_translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fffd9e-b06e-4d5a-85f6-5ba002472791",
   "metadata": {},
   "source": [
    "### True Distribution of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c825d4c5-68b0-49de-b6ec-8f883efd1cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technology\n"
     ]
    }
   ],
   "source": [
    "# Final example with true distribution of labels for categorizing news articles\n",
    "distribution_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a model that categorizes news articles into topics: Politics, Sports, Technology, or Entertainment.\"},\n",
    "    \n",
    "    # 40% Politics\n",
    "    {\"role\": \"user\", \"content\": \"Categorize this article: 'Government announces new environmental policy.'\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Politics\"},\n",
    "    {\"role\": \"user\", \"content\": \"Categorize this article: 'Elections results show surprising turn of events.'\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Politics\"},\n",
    "    \n",
    "    # 30% Sports\n",
    "    {\"role\": \"user\", \"content\": \"Categorize this article: 'Local team wins championship after dramatic final.'\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sports\"},\n",
    "    \n",
    "    # 20% Technology\n",
    "    {\"role\": \"user\", \"content\": \"Categorize this article: 'New smartphone model features the latest in AI technology.'\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Technology\"},\n",
    "    \n",
    "    # 10% Entertainment\n",
    "    {\"role\": \"user\", \"content\": \"Categorize this article: 'Famous actor stars in a new blockbuster movie.'\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Entertainment\"},\n",
    "    \n",
    "    # New article to categorize\n",
    "    {\"role\": \"user\", \"content\": \"Categorize this article: 'Breakthrough in Renewable Energy Technology Unveiled at Global Conference.'\"}\n",
    "]\n",
    "\n",
    "# Call the function with final distribution of labels for categorizing news articles\n",
    "categorization = chat_completion_request(messages=distribution_messages)\n",
    "print(categorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b25e5a7-8d03-4ba4-9376-50fe2bfa41b1",
   "metadata": {},
   "source": [
    "# Lesson 3: Lost in the Middle\n",
    "\n",
    "- is a phenomenon where the model pays more attention to the beginning and end of a text, while important details in the middle may be overlooked or given less emphasis.\n",
    "- typically occurs in long texts or complex prompts, leading to incomplete or inaccurate processing of the full content\n",
    "- somewhat similar to a person skimming through a long article and mainly remembering the introduction and conclusion, while missing key points in the middle\n",
    "- To counter this, breaking down tasks into smaller and add more context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b57a25bf-835f-4f48-b4f2-8178e076a5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Day 1: Tokyo\n",
      "**Weather:** March 1, 2024 - Mild with temperatures around 10-15°C.\n",
      "\n",
      "**Accommodation:** Stay at a traditional Japanese ryokan in Asakusa district, such as Sadachiyo Ryokan.\n",
      "\n",
      "**Morning:** Visit Senso-ji Temple in Asakusa and explore the Nakamise Shopping Street.\n",
      "\n",
      "**Lunch:** Head to Kinozen for allergy-friendly tempura and udon noodles.\n",
      "\n",
      "**Afternoon:** Take a boat cruise on the Sumida River and visit the Edo-Tokyo Museum.\n",
      "\n",
      "**Dinner:** Enjoy a traditional kaiseki meal at Ishikawa in Kagurazaka.\n",
      "\n",
      "**Cultural Event:** Participate in a tea ceremony at Happoen Garden.\n",
      "\n",
      "**Transportation:** Use the Tokyo Metro for getting around the city.\n",
      "\n",
      "**Language Tip:** Learn basic Japanese phrases like \"Arigatou\" (Thank you) and \"Sumimasen\" (Excuse me).\n",
      "\n",
      "**Etiquette:** Remember to bow when greeting others and remove your shoes before entering a traditional Japanese establishment.\n",
      "\n",
      "### Day 2: Tokyo\n",
      "**Weather:** March 2, 2024 - Sunny with temperatures around 12-17°C.\n",
      "\n",
      "**Morning:** Explore the Tsukiji Outer Market for fresh seafood and local snacks.\n",
      "\n",
      "**Lunch:** Try vegan-friendly sushi at Sushi M in Ginza.\n",
      "\n",
      "**Afternoon:** Visit the teamLab Borderless digital art museum in Odaiba.\n",
      "\n",
      "**Dinner:** Dine at Toritama in Ebisu for yakitori.\n",
      "\n",
      "**Relaxation:** Unwind at Oedo Onsen Monogatari in Odaiba.\n",
      "\n",
      "**Transportation:** Consider renting bicycles to explore areas like Asakusa and Ueno.\n",
      "\n",
      "**Cultural Event:** Attend a taiko drumming workshop at Taiko Center in Asakusa.\n",
      "\n",
      "### Day 3: Kyoto\n",
      "**Weather:** March 3, 2024 - Cool with temperatures around 8-13°C.\n",
      "\n",
      "**Accommodation:** Stay at a Machiya townhouse in Kyoto, such as Guesthouse Soi.\n",
      "\n",
      "**Morning:** Visit Fushimi Inari Taisha Shrine and hike through the thousands of torii gates.\n",
      "\n",
      "**Lunch:** Try allergy-friendly tofu dishes at Tousuiro in Gion.\n",
      "\n",
      "**Afternoon:** Explore the historic district of Higashiyama and visit Kiyomizu-dera Temple.\n",
      "\n",
      "**Dinner:** Enjoy a vegetarian shojin ryori meal at Shigetsu in Tenryu-ji Temple.\n",
      "\n",
      "**Shopping:** Browse for traditional crafts at Nishiki Market.\n",
      "\n",
      "**Transportation:** Take the Shinkansen from Tokyo to Kyoto for a fast and eco-friendly journey.\n",
      "\n",
      "**Language Tip:** Learn phrases like \"Konnichiwa\" (Hello) and \"Oishii desu\" (It's delicious).\n",
      "\n",
      "**Etiquette:** Be mindful of your volume in public spaces and avoid eating while walking.\n",
      "\n",
      "### Day 4: Kyoto\n",
      "**Weather:** March 4, 2024 - Cloudy with temperatures around 10-15°C.\n",
      "\n",
      "**Morning:** Visit Arashiyama Bamboo Grove and the Monkey Park.\n",
      "\n",
      "**Lunch:** Try matcha desserts at Saryo Tsujiri in Higashiyama.\n",
      "\n",
      "**Afternoon:** Explore the traditional machiya houses in Ninen-zaka and Sannen-zaka.\n",
      "\n",
      "**Dinner:** Dine at Ganko Sushi for fresh sushi and sashimi.\n",
      "\n",
      "**Relaxation:** Soak in an outdoor onsen at Kurama Onsen.\n",
      "\n",
      "**Cultural Event:** Participate in a traditional tea ceremony at Camellia Tea Ceremony.\n",
      "\n",
      "**Transportation:** Use the Kyoto City Bus for convenient access to major sights.\n",
      "\n",
      "### Day 5: Osaka\n",
      "**Weather:** March 5, 2024 - Mild with temperatures around 12-17°C.\n",
      "\n",
      "**Accommodation:** Stay at a guesthouse in the Shinsekai district, like Guest House Gloire.\n",
      "\n",
      "**Morning:** Visit Osaka Castle and stroll through the Osaka Castle Park.\n",
      "\n",
      "**Lunch:** Try okonomiyaki at Mizuno in Dotonbori.\n",
      "\n",
      "**Afternoon:** Explore the Shinsekai neighborhood and visit Tsutenkaku Tower.\n",
      "\n",
      "**Dinner:** Dine at Kani Doraku for allergy-friendly seafood dishes.\n",
      "\n",
      "**Shopping:** Browse for souvenirs at Kuromon Ichiba Market.\n",
      "\n",
      "**Transportation:** Take the JR train from Kyoto to Osaka for a cost-effective journey.\n",
      "\n",
      "**Language Tip:** Learn expressions like \"Domo arigato gozaimasu\" (Thank you very much) and \"Ikura desu ka?\" (How much is it?).\n",
      "\n",
      "**Etiquette:** Queue patiently in lines and wait for your turn in crowded places.\n",
      "\n",
      "### Day 6: Osaka\n",
      "**Weather:** March 6, 2024 - Sunny with temperatures around 15-20°C.\n",
      "\n",
      "**Morning:** Visit the Osaka Aquarium Kaiyukan and explore the Tempozan Marketplace.\n",
      "\n",
      "**Lunch:** Try takoyaki at Takoya Dotonbori Kukuru.\n",
      "\n",
      "**Afternoon:** Take a boat cruise on the Dotonbori River.\n",
      "\n",
      "**Dinner:** Enjoy a kushikatsu meal at Daruma in Shinsekai.\n",
      "\n",
      "**Relaxation:** Relax at Spa World for a family-friendly onsen experience.\n",
      "\n",
      "**Cultural Event:** Participate in a kimono dressing workshop at Kimono Tea Ceremony Maikoya.\n",
      "\n",
      "**Transportation:** Use the Osaka Metro for getting around the city.\n",
      "\n",
      "### Day 7: Departure\n",
      "**Weather:** March 7, 2024 - Cool with temperatures around 10-15°C.\n",
      "\n",
      "**Morning:** Visit the Osaka Museum of History and learn about Japan's past.\n",
      "\n",
      "**Lunch:** Try traditional bento boxes at Ekibenya Matsuri in Osaka Station.\n",
      "\n",
      "**Afternoon:** Explore the Umeda Sky Building for panoramic views of Osaka.\n",
      "\n",
      "**Departure:** Head to Kansai International Airport for your flight back home.\n",
      "\n",
      "**Transportation:** Consider taking the airport limousine bus for a stress-free journey to the airport.\n",
      "\n",
      "**Language Tip:** Learn phrases like \"Sayonara\" (Goodbye) and \"O-genki desu ka?\" (How are you?).\n",
      "\n",
      "**Etiquette:** Dispose of trash properly and separate recyclables when possible.\n",
      "\n",
      "This itinerary aims to provide a balanced mix of cultural experiences, culinary delights, and family-friendly activities while prioritizing eco-friendly transportation options and budget-conscious accommodations. Enjoy your trip to Japan!\n"
     ]
    }
   ],
   "source": [
    "# Example showing an overloaded task for creating a detailed travel itinerary\n",
    "overloaded_itinerary_request = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a model that helps plan travel itineraries.\"},\n",
    "    {\"role\": \"user\", \"content\": (\n",
    "        \"Create a week-long travel itinerary for a trip to Japan, starting from March 1, 2024. \"\n",
    "        \"Include a day-by-day schedule covering Tokyo, Kyoto, and Osaka. \"\n",
    "        \"For each city, recommend unique, non-touristy restaurants and hidden gems, \"\n",
    "        \"specifying dishes that are both traditional and allergy-friendly. \"\n",
    "        \"Include cultural events happening during the week, particularly those that \"\n",
    "        \"allow for active participation. Suggest accommodations that are eco-friendly, \"\n",
    "        \"budget-conscious, and offer traditional experiences. Detail transportation options \"\n",
    "        \"between cities and within each city, prioritizing eco-friendly choices and cost-effectiveness. \"\n",
    "        \"Each day should have outdoor activities, historical sites, shopping in local markets, \"\n",
    "        \"and relaxation spots like onsens. Also, provide weather advice for each day, language tips, \"\n",
    "        \"and essential cultural etiquette to follow. Ensure the plan caters to a family with young children, \"\n",
    "        \"considering accessibility and family-friendly activities.\"\n",
    "    )}\n",
    "]\n",
    "\n",
    "# Call the function with the overloaded itinerary task\n",
    "overloaded_itinerary_response = chat_completion_request(messages=overloaded_itinerary_request)\n",
    "print(overloaded_itinerary_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87b0e4c1-a5f1-41d6-b2d1-abbd6cab9e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Title: The Impact of Climate Change on Global Agriculture**\n",
      "\n",
      "**Introduction:**\n",
      "Climate change is a pressing global issue that is significantly impacting agriculture around the world. As temperatures rise, weather patterns become more unpredictable, and extreme events such as droughts and floods become more frequent, farmers are facing unprecedented challenges in growing crops and raising livestock. In this article, we will explore the effects of climate change on different types of crops, how farmers are adapting to these challenges, the role of technology in mitigating the impact, and the urgent need for collective action to ensure food security in the face of a changing climate.\n",
      "\n",
      "**Effects on Different Types of Crops:**\n",
      "Climate change is affecting different types of crops in various ways. For example, rising temperatures and changing rainfall patterns are leading to reduced crop yields and quality for staple crops such as wheat, rice, and corn. Droughts are becoming more frequent in many regions, leading to water scarcity and crop failures. In contrast, some crops like coffee and cocoa are facing challenges due to shifting growing conditions and the spread of pests and diseases in new areas.\n",
      "\n",
      "**How Farmers are Adapting:**\n",
      "Farmers around the world are increasingly adopting climate-smart agricultural practices to adapt to the changing climate. These practices include crop diversification, water conservation techniques, soil conservation methods, and the use of drought-resistant crop varieties. Farmers are also exploring new ways to manage pests and diseases, improve irrigation systems, and enhance soil health to increase resilience to climate change impacts.\n",
      "\n",
      "**The Role of Technology in Addressing Challenges:**\n",
      "Technology plays a crucial role in helping farmers cope with the challenges posed by climate change. Precision agriculture techniques, such as the use of drones, sensors, and GPS technology, enable farmers to monitor crop health, soil moisture levels, and weather conditions in real-time. This data-driven approach helps farmers make informed decisions about irrigation, fertilization, and pest control, ultimately improving crop yields and sustainability. Biotechnology also plays a vital role in developing genetically modified crops that are more resilient to climate stressors, such as drought-tolerant or heat-resistant varieties.\n",
      "\n",
      "**Conclusion:**\n",
      "Climate change is posing significant threats to global agriculture, jeopardizing food security and livelihoods for millions of farmers worldwide. The effects of climate change on different types of crops are already being felt, but farmers are adapting by embracing climate-smart agricultural practices and leveraging technology to mitigate the impact. However, urgent action is needed at all levels – from individual farmers to governments and international organizations – to address the root causes of climate change and build a more sustainable and resilient food system for the future. By working together and investing in innovative solutions, we can ensure that agriculture remains productive, sustainable, and able to feed a growing global population in the face of a changing climate.\n"
     ]
    }
   ],
   "source": [
    "# Bad Example: Asking for an Entire Article in One Prompt\n",
    "full_article_request = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a model that helps write articles.\"},\n",
    "    {\"role\": \"user\", \"content\": (\n",
    "        \"Write a complete article about the impact of climate change on global agriculture. \"\n",
    "        \"Include an introduction, the effects on different types of crops, how farmers are adapting, \"\n",
    "        \"the role of technology in addressing these challenges, and a conclusion.\"\n",
    "    )}\n",
    "]\n",
    "\n",
    "# Call the function with the full article request\n",
    "full_article_response = chat_completion_request(messages=full_article_request)\n",
    "print(full_article_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "664af572-9bcd-4c20-a776-401b11788fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I. Introduction\n",
      "    A. Brief overview of climate change and its causes\n",
      "    B. Importance of agriculture in global food production\n",
      "\n",
      "II. Climate Change Effects on Agriculture\n",
      "    A. Changes in temperature and precipitation patterns\n",
      "    B. Increased frequency of extreme weather events\n",
      "    C. Impact on crop yields and quality\n",
      "    D. Disruption of planting and harvesting seasons\n",
      "    E. Spread of pests and diseases\n",
      "\n",
      "III. Regional Impacts\n",
      "    A. Effects on staple crops in different regions (e.g., wheat, rice, corn)\n",
      "    B. Vulnerability of smallholder farmers in developing countries\n",
      "    C. Water scarcity and irrigation challenges\n",
      "    D. Shifts in suitable growing areas\n",
      "\n",
      "IV. Adaptation and Mitigation Strategies\n",
      "    A. Sustainable agricultural practices\n",
      "    B. Crop diversification and breeding for resilience\n",
      "    C. Water management and conservation techniques\n",
      "    D. Policy interventions and international cooperation\n",
      "\n",
      "V. Case Studies\n",
      "    A. Examples of successful adaptation strategies in different regions\n",
      "    B. Challenges faced by farmers and communities\n",
      "    C. Role of technology and innovation in mitigating climate impacts\n",
      "\n",
      "VI. Conclusion\n",
      "    A. Recap of the key points discussed\n",
      "    B. Call to action for policymakers, farmers, and consumers\n",
      "    C. Importance of collective efforts to address climate change impacts on agriculture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction:\n",
      "In today's fast-paced world, the importance of maintaining a healthy work-life balance cannot be overstated. Balancing the demands of a career with personal well-being and relationships is essential for overall happiness and success. This article delves into the significance of work-life balance, providing insights and practical tips to help individuals achieve harmony in their professional and personal lives. From setting boundaries and prioritizing self-care to effective time management strategies, we explore various ways to strike a balance that promotes productivity, reduces stress, and enhances overall quality of life. Join us on this journey to discover the key to a fulfilling and sustainable work-life balance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Please provide me with the article, and I will help you refine it.\n"
     ]
    }
   ],
   "source": [
    "# Good example: Breaking down the article writing process\n",
    "\n",
    "# Step 1: Asking for an outline\n",
    "outline_request = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a model that helps write article outlines.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Create an outline for an article about the impact of climate change on global agriculture.\"}\n",
    "]\n",
    "\n",
    "# Call the function for the outline\n",
    "outline_response = chat_completion_request(messages=outline_request)\n",
    "print(outline_response)\n",
    "\n",
    "# Assuming the outline is received, proceed with writing sections\n",
    "\n",
    "# Step 2: Writing individual sections (Example: Writing the introduction)\n",
    "introduction_request = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a model that helps write article sections.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write the introduction for the article based on the provided outline.\"}\n",
    "]\n",
    "\n",
    "# Call the function for the introduction section\n",
    "introduction_response = chat_completion_request(messages=introduction_request)\n",
    "print(introduction_response)\n",
    "\n",
    "# Similarly, continue with other sections...\n",
    "\n",
    "# Step 3: Refining the entire article\n",
    "# This step is done after all sections are written\n",
    "article_refinement_request = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a model that helps refine articles.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Here is the complete article [insert the written article]. Can you suggest improvements?\"}\n",
    "]\n",
    "\n",
    "# Call the function for refining the article\n",
    "article_refinement_response = chat_completion_request(messages=article_refinement_request)\n",
    "print(article_refinement_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d01abb-ba8a-47a5-b9f7-ec2e380f311b",
   "metadata": {},
   "source": [
    "# Lesson 4: Markdown Tricks\n",
    "\n",
    "- Markdown Basics: Markdown is a lightweight markup language that allows for easy text formatting using plain text syntax. It's widely used for creating formatted text on the web.\n",
    "\n",
    "- Simplicity and Readability: One of the key features of Markdown is its simplicity. The syntax is designed to be readable and straightforward, making it easy to write and read even in its raw form.\n",
    "\n",
    "## In short:\n",
    "- Use Markdown to create a clear and concise structure for your prompts.\n",
    "- Use Markdown to highlight important information in your prompts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c1932d9-b62c-49f3-839b-14a5987011d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Here are the markdown indicators for ChatGPT :\n",
    "#     1. # Heading 1\n",
    "#     2. ## Heading 2\n",
    "#     3. ### Heading 3\n",
    "#     4. *italic text*, **bold text**, __underlined text__\n",
    "#     5. [Hyperlink text](url)\n",
    "#     6. ![Image name](image url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c87247ba-ad80-4faf-9b0d-320a22e14b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Task List:\n",
      "\n",
      "1. **Research Task**:\n",
      "   - Compile a list of the top 5 AI trends in 2024.\n",
      "   - **Due Date**: Next Monday\n",
      "\n",
      "2. **Writing Task**:\n",
      "   - Write a summary of each trend, emphasizing their impact on healthcare.\n",
      "   - **Due Date**: Wednesday\n",
      "\n",
      "3. **Presentation Task**:\n",
      "   - Create a slide deck for the AI trends with appropriate visuals.\n",
      "   - Make it engaging and informative.\n",
      "   - **Due Date**: Friday\n",
      "\n",
      "4. **Feedback Session**:\n",
      "   - Organize a team meeting to discuss the slide deck.\n",
      "   - Invite all project members.\n",
      "   - **Due Date**: Next Friday\n",
      "\n",
      "### Priorities:\n",
      "- **Quality of Research**: Ensure accurate information in the trends.\n",
      "- **Clarity in Presentation**: Make the slide deck engaging and informative.\n"
     ]
    }
   ],
   "source": [
    "# Example of multi-task instruction with emphasis and list organization using Markdown\n",
    "multi_task_instruction_request = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a model that understands and organizes tasks using Markdown.\"},\n",
    "    {\"role\": \"user\", \"content\": (\n",
    "        \"Here's a list of tasks I need you to perform. Please pay **special attention** to the deadlines:\\n\\n\"\n",
    "        \"* **Research Task**: Compile a list of the top 5 AI trends in 2024. *Due: Next Monday*\\n\"\n",
    "        \"* **Writing Task**: Write a summary of each trend, emphasizing their impact on healthcare. **Ensure accuracy** in data. *Due: Wednesday*\\n\"\n",
    "        \"* **Presentation Task**: Create a slide deck for the AI trends with appropriate visuals. Remember to make it **engaging and informative**. *Due: Friday*\\n\"\n",
    "        \"* **Feedback Session**: Organize a team meeting to discuss the slide deck. Ensure to invite all project members. *Due: Next Friday*\\n\\n\"\n",
    "        \"__Note__: The quality of research and clarity in the presentation are crucial. Please prioritize these aspects.\"\n",
    "    )}\n",
    "]\n",
    "\n",
    "# Call the function to organize and emphasize the tasks\n",
    "multi_task_instruction_response = chat_completion_request(messages=multi_task_instruction_request)\n",
    "print(multi_task_instruction_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98b9e21f-0591-4902-a9c4-9324799ca960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"selected_function\": \"get_order_status\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Example of selecting a function with Markdown organization and JSON response\n",
    "function_selection_request = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a model that selects functions and formats responses in JSON.\"},\n",
    "    {\"role\": \"user\", \"content\": (\n",
    "        \"Below is a list of functions. Read the descriptions and select the most relevant function based on the user query. \"\n",
    "        \"Respond in JSON format. If the necessary information is not available, return an empty JSON response.\\n\\n\"\n",
    "        \n",
    "        \"### Available Functions:\\n\\n\"\n",
    "        \n",
    "        \"1. **get_order_status**: Retrieve order details including status and tracking information. \"\n",
    "        \"*Required Input*: Order ID, Email, or Phone Number.\\n\\n\"\n",
    "        \n",
    "        \"2. **manage_order_change_request**: Handle modifications to an existing order. \"\n",
    "        \"*Required Input*: Order ID, Email, or Phone Number.\\n\\n\"\n",
    "        \n",
    "        \"3. **get_public_info**: Access store-specific public information like policies and promotions. \"\n",
    "        \"*Required Input*: None\\n\\n\"\n",
    "        \n",
    "        \"### User Query: 'I want to know when my order will arrive.'\\n\\n\"\n",
    "        \"Based on the query, select the appropriate function and provide a JSON response.\"\n",
    "    )}\n",
    "]\n",
    "\n",
    "# Call the function to select and format the response\n",
    "function_selection_response = chat_completion_request(messages=function_selection_request)\n",
    "print(function_selection_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e21f26a-f761-43fc-83c8-5cbc7708baaa",
   "metadata": {},
   "source": [
    "# Lesson 5: Prompt Order Sensitivity\n",
    "\n",
    "- **Understand Prompt Order Sensitivity**: Recognize that the order in which examples are presented in a few-shot prompt can significantly impact an AI model's performance. Different orders can lead to varying levels of understanding and accuracy.\n",
    "\n",
    "- **Experiment with Different Orders**: To identify the most effective prompt order, experiment with rearranging your examples. This trial-and-error approach can reveal which sequence yields the best responses from the model.\n",
    "\n",
    "- **Start with Simple to Complex Examples**: When uncertain, a good rule of thumb is to arrange examples from the simplest to the most complex. This can help the model build its understanding progressively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad6e80-1498-4e48-9d83-35d316df6807",
   "metadata": {},
   "source": [
    "### LongContextReorder in LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b008a29a-bba1-41d6-a3a6-2922211da7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Engine Response:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Yes, the author met Sam Altman during the first batch of Y Combinator's Summer Founders Program. Altman would later become the second president of Y Combinator."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reorder Engine Response:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Yes, the author met Sam Altman during the first batch of startups funded by Y Combinator. Altman would later become the second president of YC. The author also mentions that Altman initially declined the offer to be president, but eventually agreed in October 2013. The author stepped back from running YC in 2013 to focus on his mother's illness, and officially retired in March 2014. After retiring, the author pursued painting and writing essays before returning to working on Lisp in March 2015."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from learn_ai.scripts.rag_llama_index_reorder import LlamaIndexQueryEngine\n",
    "\n",
    "data_dir = \"../data/paul_graham\"\n",
    "query_engine = LlamaIndexQueryEngine(data_dir)\n",
    "\n",
    "query = \"Did the author meet Sam Altman?\"\n",
    "\n",
    "print(\"Base Engine Response:\")\n",
    "base_response = query_engine.query_base_engine(query)\n",
    "\n",
    "print(\"\\nReorder Engine Response:\")\n",
    "reorder_response = query_engine.query_reorder_engine(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a85a665-ceb4-42cf-82a3-a12eff17f2b3",
   "metadata": {},
   "source": [
    "### LongContextReorder in Langchain\n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/retrievers/long_context_reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fedfd6e-22d8-48dd-9e81-f32e0665ca67",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Directory not found: './data/paul_graham/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlearn_ai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrag_langchain_reorder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LangChainQueryEngine\n\u001b[1;32m      3\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/paul_graham/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m \u001b[43mLangChainQueryEngine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid the author meet Sam Altman?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBase Engine Response:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/github/Learn-AI-Engineering/learn_ai/scripts/rag_langchain_reorder.py:30\u001b[0m, in \u001b[0;36mLangChainQueryEngine.__init__\u001b[0;34m(self, data_dir)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreorder \u001b[38;5;241m=\u001b[39m LongContextReorder()\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_index()\n",
      "File \u001b[0;32m~/Desktop/github/Learn-AI-Engineering/learn_ai/scripts/rag_langchain_reorder.py:35\u001b[0m, in \u001b[0;36mLangChainQueryEngine._load_documents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     34\u001b[0m     loader \u001b[38;5;241m=\u001b[39m DirectoryLoader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir, show_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 35\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# initialize the text splitter\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(\n\u001b[1;32m     39\u001b[0m         chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     40\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/envs/learn_ai_eng/lib/python3.11/site-packages/langchain_community/document_loaders/directory.py:117\u001b[0m, in \u001b[0;36mDirectoryLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load documents.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/envs/learn_ai_eng/lib/python3.11/site-packages/langchain_community/document_loaders/directory.py:123\u001b[0m, in \u001b[0;36mDirectoryLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m p \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory not found: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m p\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected directory, got file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Directory not found: './data/paul_graham/'"
     ]
    }
   ],
   "source": [
    "from learn_ai.scripts.rag_langchain_reorder import LangChainQueryEngine\n",
    "\n",
    "data_dir = \"../data/paul_graham\"\n",
    "query_engine = LangChainQueryEngine(data_dir)\n",
    "\n",
    "query = \"Did the author meet Sam Altman?\"\n",
    "\n",
    "print(\"Base Engine Response:\")\n",
    "base_response = query_engine.run_query(query)\n",
    "print(base_response)\n",
    "\n",
    "print(\"\\nReorder Engine Response:\")\n",
    "reorder_response = query_engine.run_query(query, reordered=True)\n",
    "print(reorder_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee58e41-b079-4f8c-8bcb-f2dbf5eb5195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed214490-61d1-4e48-a6d0-b5d61f03e4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
