{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who is this course useful for? \n",
    "\n",
    "Folks wanting to move left in this diagram:\n",
    "\n",
    "![](../assets/ai_engineer.jpeg)\n",
    "\n",
    "Figure from [Latent Space](https://www.latent.space/p/ai-engineer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But why do we need a new term for this?\n",
    "\n",
    "The term \"AI Engineer\" may or may not go mainstream: What we definitely need are software engineers who can work with LLMs (large language models) and other related components of AI systems.\n",
    "\n",
    "While the software engineer focussed a lot more on code design, infrastructure and similar concerns -- the AI engineer focusses a lot more on data.\n",
    "\n",
    "![](../assets/data_first.png)\n",
    "\n",
    "From [Google's Search Engineering](https://t.co/DqRlUMKI9C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we assume you know\n",
    "This course is structured around the assumption that you are a proficient engineer first, which means you are able to reason about deterministic systems despite their complexity. We assume you're proficient in at least one of Python or JS and can deploy a simple GET with \"Hello World\" over REST in less than 10 minutes of effort. \n",
    "\n",
    "## What we focus on\n",
    "1. Experiential Teaching: Examples and use cases which we have seen ourselves but that is nowhere exhausted compared to what you might see on the job depending on your specialization. \n",
    "2. Text-first: We focus a lot more on text than vision, sound, audio or video at least at the moment. This is partially because most enterprise applications of Generative AI today are text first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How mainstream is this?\n",
    "\n",
    "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">CMU now advertising their AI Engineering degrees in The Atlantic (?!) print media<br><br>how mainstream is this thing becoming. Feels bubbly. uh oh <a href=\"https://t.co/Y4XOvZumZq\">pic.twitter.com/Y4XOvZumZq</a></p>&mdash; swyx (@swyx) <a href=\"https://twitter.com/swyx/status/1745129994828067057?ref_src=twsrc%5Etfw\">January 10, 2024</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What skills are people looking for?\n",
    "\n",
    "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Trying to write a JD to hire software engineers that build with LLMs.<br><br>Beyond making REST calls, what&#39;s essential? Some I can think of:<br><br>• Evals: Collect labels &amp; measure task performance<br>• Look at lots of data: Debugging prompts, error analysis<br>• Comfort with probabilistic…</p>&mdash; Eugene Yan (@eugeneyan) <a href=\"https://twitter.com/eugeneyan/status/1753445305545298314?ref_src=twsrc%5Etfw\">February 2, 2024</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "\n",
    "Eugene Yan is a Principal Engineer at Amazon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "\n",
    "This section is about generating text using LLMs. This is the most common use case for LLMs. We will cover how to write prompts, how to set parameters for the LLMs, and how to generate text. This is based on [How to format inputs to ChatGPT models](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb) from OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example OpenAI Python library request\n",
    "MODEL = \"gpt-3.5-turbo-0125\"\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Orange.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-9H04WxcElMvSRjhtzrLF0E62FiwIL\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Orange who?\",\n",
      "                \"role\": \"assistant\",\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1713838880,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"system_fingerprint\": \"fp_c2295e73ad\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 3,\n",
      "        \"prompt_tokens\": 35,\n",
      "        \"total_tokens\": 38\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json.loads(response.model_dump_json()), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting just the reply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Orange who?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In May, Nagpur typically experiences hot weather with temperatures ranging from 30°C to 45°C (86°F to 113°F). The weather is usually dry with very little rainfall during this month. It is advisable to stay hydrated and wear light clothing to stay comfortable in the heat.\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "# An example of a system message that primes the assistant to be verbose and helpful\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a friendly and helpful teaching assistant.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"Describe the weather in Nagpur in May\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "(print(response.choices[0].message.content),)\n",
    "print(response.usage.completion_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
